# training_config.yaml
# Configuration file for VLM training

model:
  model_path: "path/to/pretrained/paligemma/model"
  freeze_vision_encoder: true
  max_length: 512

data:
  train_data_path: "data/train.jsonl"
  val_data_path: "data/val.jsonl"
  batch_size: 8
  num_workers: 4

training:
  num_epochs: 3
  learning_rate: 2e-5
  warmup_steps: 1000
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  weight_decay: 0.01

optimization:
  optimizer: "adamw"
  scheduler: "cosine_with_warmup"
  mixed_precision: true

logging:
  log_interval: 100
  save_steps: 1000
  output_dir: "./checkpoints"
  use_wandb: false
  wandb_project: "vlm-training"
  wandb_run_name: null

hardware:
  only_cpu: false
  device: "auto"  # auto, cuda, mps, cpu

# Dataset preparation configs
datasets:
  conceptual_captions:
    csv_path: "data/conceptual_captions/Train_GCC-training.tsv"
    max_samples: 100000
    min_image_size: 224
    
  coco_captions:
    images_dir: "data/coco/images"
    annotations_file: "data/coco/